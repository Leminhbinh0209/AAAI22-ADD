# ADD: Frequency Attention and Multi-View based Knowledge Distillation to Detect Low-Quality Compressed Deepfake Images

*Thirty-Sixth AAAI Conference on Artificial Intelligence. 2022. Canada* <br />
[[paper](https://arxiv.org/abs/2112.03553)]<br />

<img alt="GitHub top language" src="https://img.shields.io/github/languages/top/Leminhbinh0209/ADD?style=for-the-badge" height="25"><img alt="GitHub last commit" src="https://img.shields.io/github/last-commit/Leminhbinh0209/ADD?style=for-the-badge" height="25"><img alt="GitHub repo size" src="https://img.shields.io/github/repo-size/Leminhbinh0209/ADD?style=for-the-badge" height="25">
<br />



## Overview of our framework
<p align="center">
    <img src="https://i.ibb.co/KmxVRQw/overall-pipeline.png" width="960" alt="overall pipeline">
<p>
    
## Installation
- Ubuntu 18.04.5 LTS
- CUDA 10.2
- Python 3.6.10
- python packages are detailed separately in ```requirements.txt```.

    
## Datasets 
* NeuralTextures [[Dataset]](https://github.com/ondyari/FaceForensics) [[Paper]](https://arxiv.org/abs/1904.12356) 
* DeepFakes [[Dataset]](https://github.com/ondyari/FaceForensics)  [[GitHub]](https://github.com/deepfakes/faceswap)
* Face2Face [[Dataset]](https://github.com/ondyari/FaceForensics) [[Paper]](https://arxiv.org/abs/2007.14808)
* FaceSwap [[Dataset]](https://github.com/ondyari/FaceForensics) [[GitHub]](https://github.com/deepfakes/faceswap)
* FaceShifter [[Dataset]](https://github.com/ondyari/FaceForensics)  [[Paper]](https://arxiv.org/abs/1912.13457) 

## Grad-CAM
<p align="center">
    <img src="https://i.ibb.co/WzKGnCz/gradcam-fake-bb2-background.png" width="540" alt="Grad-CAM">
<p>
    
##  Citation
*Star (‚≠ê) if you find it useful, and consider to cite our work*  

```
@inproceedings{le2022add,
  title={ADD: Frequency attention and multi-view based knowledge distillation to detect low-quality compressed deepfake images},
  author={Le, Binh M and Woo, Simon S},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={1},
  pages={122--130},
  year={2022}
}
```
